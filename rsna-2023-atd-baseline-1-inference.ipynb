{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nIn this notebook, we are going to use our previously trained CNN model (refer RSNA 2023 ATD - Baseline 1 [Training](https://www.kaggle.com/code/pankajpansari/rsna-2023-atd-baseline-1-training) notebook) to make prediction on unseen CT scans. We are also going to use this notebook to make our submission for the competition. We make use of the [fastai](https://docs.fast.ai) library.\n\nThe advantage of separating the training and inference parts of the pipeline is that we don't need to spend time and compute retraining our model in the cloud. We can simply import the saved model and make predictions. Moreover, this separation enables more flexible development. We can focus on improving training or speeding up inference in an indepenedent way.\n\nOur model makes predictions on individual images. There are sequence of images for each patient. We need to take the image-level predictions and aggregrate them to make prediction for each patient.","metadata":{}},{"cell_type":"markdown","source":"## Code\n\nWe're going to import the necessary libraries.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, random\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nimport shutil\nimport pydicom\nimport cv2\nimport glob\nimport time\nfrom rsna_2023_atd_metric import score\n\nfrom PIL import Image\n\nrandom.seed(1441)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.084076Z","iopub.execute_input":"2023-09-23T08:42:00.084527Z","iopub.status.idle":"2023-09-23T08:42:00.093994Z","shell.execute_reply.started":"2023-09-23T08:42:00.084482Z","shell.execute_reply":"2023-09-23T08:42:00.092941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def standardize_pixel_array(fn):\n    \"\"\"\n    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n    \"\"\"\n    # Correct DICOM pixel_array if PixelRepresentation == 1.\n    dcm = pydicom.dcmread(fn)\n    pixel_array = dcm.pixel_array\n    if dcm.PixelRepresentation == 1:\n        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n        dtype = pixel_array.dtype \n        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n\n    intercept = float(dcm.RescaleIntercept)\n    slope = float(dcm.RescaleSlope)\n    center = int(dcm.WindowCenter)\n    width = int(dcm.WindowWidth)\n    low = center - width / 2\n    high = center + width / 2    \n    \n    pixel_array = (pixel_array * slope) + intercept\n    pixel_array = np.clip(pixel_array, low, high)\n\n    return pixel_array","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.103676Z","iopub.execute_input":"2023-09-23T08:42:00.104048Z","iopub.status.idle":"2023-09-23T08:42:00.114279Z","shell.execute_reply.started":"2023-09-23T08:42:00.104013Z","shell.execute_reply":"2023-09-23T08:42:00.112828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PILDicom2(PILBase):\n    \"same as PILDicom but changed pixel array dtype to int32 since uint16 cannot be handled by PIL/PyTorch\"\n    \n    _open_args,_tensor_cls,_show_args = {},TensorDicom,TensorDicom._show_args\n    @classmethod\n    def create(cls, fn:Path|str|bytes, mode=None)->None:\n        \"Open a `DICOM file` from path `fn` or bytes `fn` and load it as a `PIL Image`\"\n        if isinstance(fn,bytes): im = Image.fromarray(pydicom.dcmread(pydicom.filebase.DicomBytesIO(fn)).pixel_array)\n        if isinstance(fn,(Path,str)): im = Image.fromarray(standardize_pixel_array(fn).astype(np.int32))\n        im.load()\n        im = im._new(im.im)\n        return cls(im.convert(mode) if mode else im)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.117730Z","iopub.execute_input":"2023-09-23T08:42:00.119937Z","iopub.status.idle":"2023-09-23T08:42:00.135341Z","shell.execute_reply.started":"2023-09-23T08:42:00.119901Z","shell.execute_reply":"2023-09-23T08:42:00.134360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadModel(Module):\n    \n    def __init__(self, body):\n    \n        self.body = body\n        nf = num_features_model(nn.Sequential(*self.body.children()))\n\n        self.bowel = create_head(nf, 1)\n        self.extravasation = create_head(nf, 1)\n        self.kidney = create_head(nf, 3)\n        self.liver = create_head(nf, 3)\n        self.spleen = create_head(nf, 3)\n        \n    def forward(self, x):\n        \n        y = self.body(x)\n        bowel = self.bowel(y)\n        extravasation = self.extravasation(y)\n        kidney = self.kidney(y)\n        liver = self.liver(y)\n        spleen = self.spleen(y)\n        return [bowel, extravasation, kidney, liver, spleen]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.140990Z","iopub.execute_input":"2023-09-23T08:42:00.141887Z","iopub.status.idle":"2023-09-23T08:42:00.156846Z","shell.execute_reply.started":"2023-09-23T08:42:00.141852Z","shell.execute_reply":"2023-09-23T08:42:00.155837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CombinationLoss(Module):\n    \"Cross entropy loss on multiple targets\"\n    def __init__(self, func = F.cross_entropy, weights = [2, 6, 3, 3, 3]):\n        self.func = func\n        self.w = weights\n        \n    def forward(self, xs, *ys, reduction = 'mean'):\n        loss = 0\n    \n        for i, w, x, y in zip(range(len(xs)), self.w, xs, ys):\n            if i < 2:\n                loss += w*F.binary_cross_entropy_with_logits(x, y.unsqueeze(1).float(), reduction = reduction)\n            else:\n                #import pdb;pdb.set_trace()\n                loss += w*F.cross_entropy(x, y, reduction = reduction)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.160405Z","iopub.execute_input":"2023-09-23T08:42:00.161527Z","iopub.status.idle":"2023-09-23T08:42:00.177751Z","shell.execute_reply.started":"2023-09-23T08:42:00.161492Z","shell.execute_reply":"2023-09-23T08:42:00.176752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import recall_score\n\nclass RecallPartial(Metric):\n    \"Stores predictions and targets on CPU in accumulate to perform final calculations with `func`.\"\n    def __init__(self, a=0, **kwargs):\n        self.func = partial(recall_score, average='macro', zero_division=0)\n        self.a = a\n\n    def reset(self): self.targs,self.preds = [],[]\n\n    def accumulate(self, learn):\n        pred = learn.pred[self.a].argmax(-1)\n        targ = learn.y[self.a]\n        pred,targ = to_detach(pred),to_detach(targ)\n        pred,targ = flatten_check(pred,targ)\n        self.preds.append(pred)\n        self.targs.append(targ)\n\n    @property\n    def value(self):\n        if len(self.preds) == 0: return\n        preds,targs = torch.cat(self.preds),torch.cat(self.targs)\n        return self.func(targs, preds)\n\n    @property\n    def name(self): return 'recall_' + str(self.a+1)\n    \nclass RecallCombine(Metric):\n    def accumulate(self, learn):\n        scores = [learn.metrics[i].value for i in range(3)]\n        self.combine = np.average(scores, weights=[2,1,1])\n\n    @property\n    def value(self):\n        return self.combine","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.181834Z","iopub.execute_input":"2023-09-23T08:42:00.182575Z","iopub.status.idle":"2023-09-23T08:42:00.202915Z","shell.execute_reply.started":"2023-09-23T08:42:00.182538Z","shell.execute_reply":"2023-09-23T08:42:00.201913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We load the saved model. Note that we want our model to load on the GPU, because we're going to use GPU for inference. To ensure this, we need to set the _cpu_ option to __False__, else the model gets loaded on the CPU by default.","metadata":{}},{"cell_type":"code","source":"learn = load_learner('/kaggle/input/rsna-2023-atd-baseline-1-training/model.pt', cpu = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.208060Z","iopub.execute_input":"2023-09-23T08:42:00.214018Z","iopub.status.idle":"2023-09-23T08:42:00.716479Z","shell.execute_reply.started":"2023-09-23T08:42:00.213972Z","shell.execute_reply":"2023-09-23T08:42:00.715392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The original train/test CT scan images are in DICOM format, but we're going to use the PNG format for making predictions.","metadata":{}},{"cell_type":"code","source":"TEST_PATH = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/'\nNUM_SCANS = 256\n\nprint('Number of test patients:', len(os.listdir(TEST_PATH)))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.718266Z","iopub.execute_input":"2023-09-23T08:42:00.718943Z","iopub.status.idle":"2023-09-23T08:42:00.729059Z","shell.execute_reply.started":"2023-09-23T08:42:00.718908Z","shell.execute_reply":"2023-09-23T08:42:00.727286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the following, we loop over the patients. For each patient, we convert the DICOM images to rescaled PNG images and save them. Then, we make a dataloader using these images and make predictions. We keep the batch size relatively high to make good use of GPU. We save the predictions in a list and delete the images since we don't need them further.","metadata":{}},{"cell_type":"code","source":"def merge_arr(a, b):\n    return np.concatenate((a, b.numpy()), axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.731507Z","iopub.execute_input":"2023-09-23T08:42:00.734212Z","iopub.status.idle":"2023-09-23T08:42:00.740556Z","shell.execute_reply.started":"2023-09-23T08:42:00.734177Z","shell.execute_reply":"2023-09-23T08:42:00.739473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patients = random.choices(os.listdir(TEST_PATH), k = 10)\n\nbowel_preds, extrav_preds = np.array([]).reshape(0), np.array([]).reshape(0)\nkidney_preds, liver_preds, spleen_preds = np.array([]).reshape(0, 3), np.array([]).reshape(0, 3), np.array([]).reshape(0, 3)\nfnames_list = []\n\nstart = time.time()\nsigm = torch.nn.Sigmoid()\nsoftm = torch.nn.Softmax(dim = 1)\n\nfor idx, patient in enumerate(patients):\n    \n    series = os.listdir(os.path.join(TEST_PATH, patient))\n    \n    for s in series:\n        \n        files = random.choices(os.listdir(os.path.join(TEST_PATH, patient, s)), k = NUM_SCANS)\n        files = [os.path.join(TEST_PATH, patient, s, f) for f in files]\n        test_dl = learn.dls.test_dl(files, with_labels = False, device = 'cuda', bs = 256)\n\n        preds = learn.get_preds(dl = test_dl)[0]\n        \n        bowel_preds = merge_arr(bowel_preds, sigm(preds[0]).squeeze(-1))\n        extrav_preds = merge_arr(extrav_preds, sigm(preds[1]).squeeze(-1))\n        kidney_preds = merge_arr(kidney_preds, softm(preds[2]))\n        liver_preds = merge_arr(liver_preds, softm(preds[3]))\n        spleen_preds = merge_arr(spleen_preds, softm(preds[4]))\n       \n        fnames_list.append(files)\n\n    if (idx + 1) % 100 == 0:\n        end = time.time()\n        print(f'{idx + 1} patients processed.')\n        print(f'Time elapsed: {end - start} ')\n        print(f'Avg time per patient: {(end - start)/(idx + 1)}')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:42:00.742242Z","iopub.execute_input":"2023-09-23T08:42:00.743113Z","iopub.status.idle":"2023-09-23T08:44:10.458413Z","shell.execute_reply.started":"2023-09-23T08:42:00.743078Z","shell.execute_reply":"2023-09-23T08:44:10.457319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We convert the prediction list to a numpy array.","metadata":{}},{"cell_type":"code","source":"from itertools import chain\nfnames_list = list(chain.from_iterable(fnames_list))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.465438Z","iopub.execute_input":"2023-09-23T08:44:10.467762Z","iopub.status.idle":"2023-09-23T08:44:10.475114Z","shell.execute_reply.started":"2023-09-23T08:44:10.467724Z","shell.execute_reply":"2023-09-23T08:44:10.474216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the predictions, we derive the individual probabilities for different conditions. Our predictions are the probabilities of injury in bowel, extravasation, liver, kidney, and spleen. The probability of the organs being healthy is naturally 1 - probability of injury. We take the probability of liver, kidney, and  spleen injury and divide them equally between low and high types.","metadata":{}},{"cell_type":"code","source":"test_files_probs = pd.DataFrame()\n\ntest_files_probs['fname'] = pd.Series(fnames_list, dtype = 'string')\n\ntest_files_probs['bowel_healthy'] = pd.Series(1 - bowel_preds)\ntest_files_probs['bowel_injury'] = pd.Series(bowel_preds)\ntest_files_probs['extravasation_healthy'] = pd.Series(1 - extrav_preds)\ntest_files_probs['extravasation_injury'] = pd.Series(extrav_preds)\ntest_files_probs['kidney_healthy'] = pd.Series(kidney_preds[:, 0])\ntest_files_probs['kidney_low'] = pd.Series(kidney_preds[:, 1])\ntest_files_probs['kidney_high'] = pd.Series(kidney_preds[:, 2])\ntest_files_probs['liver_healthy'] = pd.Series(liver_preds[:, 0])\ntest_files_probs['liver_low'] = pd.Series(liver_preds[:, 1])\ntest_files_probs['liver_high'] = pd.Series(liver_preds[:, 2])\ntest_files_probs['spleen_healthy'] = pd.Series(spleen_preds[:, 0])\ntest_files_probs['spleen_low'] = pd.Series(spleen_preds[:, 1])\ntest_files_probs['spleen_high'] = pd.Series(spleen_preds[:, 2])\n\n#test_files_probs","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.480199Z","iopub.execute_input":"2023-09-23T08:44:10.482940Z","iopub.status.idle":"2023-09-23T08:44:10.515175Z","shell.execute_reply.started":"2023-09-23T08:44:10.482904Z","shell.execute_reply":"2023-09-23T08:44:10.514300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We add a new column _'patient_id'_ derived from file name. This will be helpful in aggregating the predictions from image-level to patient-level.","metadata":{}},{"cell_type":"code","source":"patient_id_list = []\nfor idx, fname in enumerate(test_files_probs['fname']):\n    patient_id_list.append(fname.split('/')[-3])\n    \ntest_files_probs['patient_id'] = pd.Series(patient_id_list, dtype = 'string')\n\ntest_files_probs = test_files_probs.drop('fname', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.519243Z","iopub.execute_input":"2023-09-23T08:44:10.521521Z","iopub.status.idle":"2023-09-23T08:44:10.545191Z","shell.execute_reply.started":"2023-09-23T08:44:10.521485Z","shell.execute_reply":"2023-09-23T08:44:10.544174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We simply take the mean over the predictons of all the CT scan images for each patient to make the prediction for each patient.","metadata":{"execution":{"iopub.status.busy":"2023-09-22T10:45:57.923460Z","iopub.execute_input":"2023-09-22T10:45:57.923920Z","iopub.status.idle":"2023-09-22T10:45:57.973481Z","shell.execute_reply.started":"2023-09-22T10:45:57.923881Z","shell.execute_reply":"2023-09-22T10:45:57.972099Z"}}},{"cell_type":"code","source":"patient_probs = test_files_probs.groupby('patient_id').mean()\n\npatient_probs.insert(0, 'patient_id', patient_probs.index)\n\npatient_probs = patient_probs.reset_index(drop = True)\npatient_probs.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.549216Z","iopub.execute_input":"2023-09-23T08:44:10.551453Z","iopub.status.idle":"2023-09-23T08:44:10.593417Z","shell.execute_reply.started":"2023-09-23T08:44:10.551417Z","shell.execute_reply":"2023-09-23T08:44:10.592553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we write the predictions for all patients to _submission.csv_ file and submit our notebook.","metadata":{}},{"cell_type":"code","source":"patient_probs.to_csv('submission.csv', header = True, index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.597428Z","iopub.execute_input":"2023-09-23T08:44:10.599685Z","iopub.status.idle":"2023-09-23T08:44:10.610812Z","shell.execute_reply.started":"2023-09-23T08:44:10.599650Z","shell.execute_reply":"2023-09-23T08:44:10.609686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Computing Evaluation Metric on a Dataset","metadata":{}},{"cell_type":"code","source":"solution = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv')\nsolution.patient_id = solution.patient_id.astype(str)\n\nsolution = solution[solution.patient_id.isin(patient_probs.patient_id)]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.615234Z","iopub.execute_input":"2023-09-23T08:44:10.617476Z","iopub.status.idle":"2023-09-23T08:44:10.645237Z","shell.execute_reply.started":"2023-09-23T08:44:10.617441Z","shell.execute_reply":"2023-09-23T08:44:10.644091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solution['bowel_weight'] = pd.Series(np.maximum(1*solution.bowel_healthy.to_numpy(), 2*solution.bowel_injury.to_numpy()))\nsolution['extravasation_weight'] = pd.Series(np.maximum(1*solution.extravasation_healthy.to_numpy(), 6*solution.extravasation_injury.to_numpy()))\nsolution['kidney_weight'] = pd.Series(np.maximum.reduce([1*solution.kidney_healthy.to_numpy(), 2*solution.kidney_low.to_numpy(), 4*solution.kidney_high.to_numpy()]))\nsolution['spleen_weight'] = pd.Series(np.maximum.reduce([1*solution.spleen_healthy.to_numpy(), 2*solution.spleen_low.to_numpy(), 4*solution.spleen_high.to_numpy()]))\nsolution['liver_weight'] = pd.Series(np.maximum.reduce([1*solution.liver_healthy.to_numpy(), 2*solution.liver_low.to_numpy(), 4*solution.liver_high.to_numpy()]))\nsolution['any_injury_weight'] = pd.Series([6]*solution.shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.649830Z","iopub.execute_input":"2023-09-23T08:44:10.652138Z","iopub.status.idle":"2023-09-23T08:44:10.672085Z","shell.execute_reply.started":"2023-09-23T08:44:10.652071Z","shell.execute_reply":"2023-09-23T08:44:10.670943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solution","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.673538Z","iopub.execute_input":"2023-09-23T08:44:10.674201Z","iopub.status.idle":"2023-09-23T08:44:10.703491Z","shell.execute_reply.started":"2023-09-23T08:44:10.674167Z","shell.execute_reply":"2023-09-23T08:44:10.702581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import pdb; pdb.set_trace()\nscore(solution, patient_probs, 'patient_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:28.906101Z","iopub.execute_input":"2023-09-23T08:44:28.906539Z","iopub.status.idle":"2023-09-23T08:44:29.029473Z","shell.execute_reply.started":"2023-09-23T08:44:28.906493Z","shell.execute_reply":"2023-09-23T08:44:29.027195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_probs","metadata":{"execution":{"iopub.status.busy":"2023-09-23T08:44:10.801111Z","iopub.status.idle":"2023-09-23T08:44:10.801887Z","shell.execute_reply.started":"2023-09-23T08:44:10.801626Z","shell.execute_reply":"2023-09-23T08:44:10.801650Z"},"trusted":true},"execution_count":null,"outputs":[]}]}